{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from modelscope import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "#torch.backends.cuda.enable_flash_sdp(False)\n",
    "model_name = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_news = pd.read_json('/home/userroot/dev/jiucai/crawl/sina_news/data/bak.stock_news.jsonl',lines=True)\n",
    "batch_size = 1\n",
    "line_size = df_news.shape[0]\n",
    "cnt = line_size // batch_size \n",
    "for i in range(cnt):\n",
    "    batch_news = df_news[i*batch_size:(i+1)*batch_size]\n",
    "    batch_prompts = []\n",
    "    for i, news in batch_news.iterrows():\n",
    "        #print(len(news['content']))\n",
    "        news = news['content'][0:4000]\n",
    "\n",
    "        messages = [\n",
    "            \n",
    "\n",
    "            {\"role\": \"user\", \"content\": f\"从下面内容中总结内容\\n{news}\"},\n",
    "            {\"role\":\"system\", \"content\":f\"你是一名专业的投研分析人员，你的任务是进行投研分析并总结，然后发布评论，如果无法总结，请回答不知道。总结内容不要超过150字,不允许分段。评论内容在总结内容之后，以【评论】开头\"},\n",
    "\n",
    "        ]\n",
    "        batch_prompts.append(messages)\n",
    "    #     print(len(prompt_templated))\n",
    "    #     print(tokenizer.decode(input_tensor[0]))\n",
    "    #     print(input_tensor.shape)\n",
    "    # continue\n",
    "\n",
    "    #prompt_templated = tokenizer.apply_chat_template(batch_prompts, tokenize=False, add_generation_prompt=True, return_tensors=\"pt\",truncation='only_first')\n",
    "\n",
    "    input_tensor = tokenizer.apply_chat_template(batch_prompts, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\",truncation='only_first', padding=True)\n",
    "\n",
    "    outputs = model.generate(input_tensor.to(model.device), max_new_tokens=300, temperature = 0.0000000001)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        result = tokenizer.decode(outputs[i][input_tensor.shape[1]:], skip_special_tokens=True)\n",
    "        print(f\"idx {i}: {result}\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 13:47:32,771 - modelscope - INFO - PyTorch version 2.1.2 Found.\n",
      "2024-04-07 13:47:32,774 - modelscope - INFO - Loading ast index from /home/userroot/.cache/modelscope/ast_indexer\n",
      "2024-04-07 13:47:32,821 - modelscope - INFO - Loading done! Current index file version is 1.13.3, with md5 821edacd9c7695756b5e5583d4438f12 and a total number of 972 components indexed\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-07 13:47:34 config.py:767] Casting torch.bfloat16 to torch.float16.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 13:47:37,111\tINFO worker.py:1752 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 13:47:38 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='/home/userroot/.cache/modelscope/hub/deepseek-ai/deepseek-llm-7b-chat', tokenizer='/home/userroot/.cache/modelscope/hub/deepseek-ai/deepseek-llm-7b-chat', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir='/home/userroot/.cache/modelscope/hub/deepseek-ai/deepseek-llm-7b-chat', load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 13:47:45 selector.py:40] Cannot use FlashAttention backend for Volta and Turing GPUs.\n",
      "INFO 04-07 13:47:45 selector.py:25] Using XFormers backend.\n",
      "\u001b[36m(RayWorkerVllm pid=501925)\u001b[0m INFO 04-07 13:47:47 selector.py:40] Cannot use FlashAttention backend for Volta and Turing GPUs.\n",
      "\u001b[36m(RayWorkerVllm pid=501925)\u001b[0m INFO 04-07 13:47:47 selector.py:25] Using XFormers backend.\n",
      "INFO 04-07 13:47:47 pynccl_utils.py:45] vLLM is using nccl==2.18.1\n",
      "\u001b[36m(RayWorkerVllm pid=501925)\u001b[0m INFO 04-07 13:47:47 pynccl_utils.py:45] vLLM is using nccl==2.18.1\n",
      "INFO 04-07 13:48:01 model_runner.py:104] Loading model weights took 6.4663 GB\n",
      "\u001b[36m(RayWorkerVllm pid=501925)\u001b[0m INFO 04-07 13:48:06 model_runner.py:104] Loading model weights took 6.4663 GB\n",
      "INFO 04-07 13:48:08 ray_gpu_executor.py:240] # GPU blocks: 3262, # CPU blocks: 1092\n",
      "INFO 04-07 13:48:13 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-07 13:48:13 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=501925)\u001b[0m INFO 04-07 13:48:13 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerVllm pid=501925)\u001b[0m INFO 04-07 13:48:13 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-07 13:48:21 model_runner.py:867] Graph capturing finished in 8 secs.\n",
      "\u001b[36m(RayWorkerVllm pid=501925)\u001b[0m INFO 04-07 13:48:21 model_runner.py:867] Graph capturing finished in 8 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM\n",
    "import torch\n",
    "from modelscope import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "import os\n",
    "os.environ['VLLM_USE_MODELSCOPE'] = \"True\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "model_name = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(model_name, trust_remote_code=True,dtype=torch.float16,tensor_parallel_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "\n",
      "1. 截至2023年末，工行、农行、建行私行客户数均超过20万户，中行、招行的客户数也均超过了10万户。\n",
      "2. 除招行之外，工行、中行、农行、建行的管理规模均超过2万亿元。\n",
      "3. 各银行私人银行业务经营数据表明，私行直营中心建设正在加快，“人-家-企-社”是私行业务发展的重要思路。\n",
      "\n",
      "评论：私人银行业务发展迅速，各银行在私行直营中心建设、综合营销和直接经营等方面加大力度，以满足客户需求。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "\n",
      "贵州茅台发布了2023年年报，公司营业总收入和归母净利润同比双双增长。第四季度营业总收入和归母净利润也同比双双增长。各项财务指标表现尚佳，毛利率、净利率、每股收益等指标均有所增长。资产质量方面，公司现金资产健康，存货周转天数较慢，需要进一步观察是否是行业原因。营收分析方面，公司现金流为正，经营性现金流和利润不匹配，但问题不大。公司盈利能力优秀，且稳健，业务体量和利润有过中速增长。分析师普遍预期2024年业绩在876.38亿元，每股收益均值在69.76元。\n",
      "\n",
      "评论：\n",
      "\n",
      "贵州茅台的财报显示公司业绩表现良好，各项财务指标增长明显。分析师普遍预期公司未来业绩将继续增长，但增速可能会有所减缓。基金经理对贵州茅台的持仓较为积极，易方达基金的陈皓是备受关注的基金经理之一。投资者可以关注贵州茅台的未来发展趋势，但需注意投资风险。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "奇瑞汽车股份有限公司从去年9月开始陆续申请注册“越己”商标，最新申请日期为今年2月7日，部分商标还处于“等待实质审查”阶段。奇瑞酝酿该新品牌或已多时，首款车型代号T1GC，为混动紧凑型SUV，将搭载讯飞星火大模型，配备奇瑞最新底盘。目前，奇瑞对前述推新品牌传闻并未公开置评。\n",
      "\n",
      "评论：\n",
      "奇瑞在新能源领域的动作不断，但目前来看，要争取国内新能源车头部位置仍存在一定困难。奇瑞需要进一步突破，才能在新能源汽车市场上取得更好的成绩。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "AH股溢价率前三名为东北电气、弘业期货、浙江世宝，分别达到1084.21%、780.15%、670.20%；偏离值前三名为安德利果汁、山东墨龙、弘业期货，分别为173.79%、130.82%、28.93%。\n",
      "\n",
      "评论：AH股溢价率存在较大差异，投资者需关注相关风险。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "本次抽检共涉及11家被抽样单位，共抽检了271批次食品，其中12批次不合格，不合格率为4.6%。不合格项目主要包括噻虫胺、镉(以Cd计)、铅(以Pb计)等。不合格产品主要涉及食用农产品、炒货食品及坚果制品、蔬菜制品等。\n",
      "\n",
      "评论：\n",
      "本次抽检发现的不合格食品项目和批次相对较多，说明在食品生产和流通环节仍存在一定的质量问题。相关部门应加强对不合格产品的监管和处罚力度，督促企业加强质量控制，确保食品安全。同时，消费者也应提高食品安全意识，选择正规渠道购买食品，注意查看食品标签和检验报告，确保自身权益。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次公布的监督抽检的194批，全部合格。特别提示消费者，在购买到或在市场上发现被通报的不合格产品时请拨打“12315”投诉举报电话进行投诉或举报。\n",
      "\n",
      "评论：本次抽检覆盖了食品、酒类、调味品、淀粉及淀粉制品、饼干、炒货食品及坚果制品、糕点、肉制品、方便食品、豆制品、餐饮食品、蔬菜制品、食用油、油脂及其制品、粮食加工品、食用农产品等多个类别，涵盖了消费者日常生活的方方面面。总体来看，抽检结果显示市场整体质量状况良好，消费者可以放心购买。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：金典作为中国高端乳品，自2018年起深度支持博鳌亚洲论坛，并连续六年荣膺唯一指定牛奶。金典始终保持对奶源、牧场、工艺的高要求，以高标准引领有机奶发展，并不断拓展品类创新边界。金典限定呼伦贝尔有机纯牛奶进行碳中和新升级，实现温室气体的相对“净零排放”。金典携手小罐茶等优质国货品牌，传递中国健康生活和美食文化自信。金典将持续洞察消费者需求，以守护全民健康为己任，加速创新步伐，让全球更多消费者喜爱上来自中国的“世界品质”。\n",
      "\n",
      "评论：金典作为中国有机乳品开拓者和引领者，连续六年荣膺博鳌亚洲论坛唯一指定牛奶，充分证明了品牌长期坚持做一件事的重要性。金典在产品创新、品质保障和品牌传播方面均表现出色，值得其他企业学习和借鉴。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "\n",
      "伊利股份新获得一项发明专利授权，专利名为“一种零散提手自动整理系统”，专利申请号为CN201710302886.9，授权日为2024年3月29日。今年以来伊利股份新获得专利授权66个，较去年同期减少了60.24%。公司2023上半年在研发方面投入了3.44亿元，同比增11.7%。\n",
      "\n",
      "评论：\n",
      "\n",
      "伊利股份在研发方面的投入不断增加，显示出公司对科技创新的重视。此次获得的发明专利授权，不仅体现了公司在技术研发方面的实力，也有助于提升公司的核心竞争力。随着公司研发投入的增加，未来有望推出更多创新产品，进一步巩固市场地位。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：妙可蓝多营收8年来首降，净利润腰斩，主要原因是核心打法失灵，奶酪行业不景气，头顶“奶酪第一股”的妙可蓝多最终也选择了躺平。理财比主营赚钱，研发投入不够，销量下降。\n",
      "\n",
      "评论：妙可蓝多需要寻找新的破局点，加大研发投入，推出创新产品，提高产品竞争力，同时调整市场战略，不能过于保守。在奶酪市场下行的情况下，积极寻找新的增长点，才能在竞争中脱颖而出。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "\n",
      "在博鳌亚洲论坛2024年年会分论坛“增强企业创新性”上，与会嘉宾就人工智能相关话题展开讨论。远大科技集团有限公司董事长兼总裁张跃认为，创新是为了解决问题，需要加强知识产权保护，并透露公司参与创新的人有1000多名，但90%原始方案的点子是由自己提出。小罐茶创始人、董事长杜国楹认为，创新是一种意识、能力、系统，需要企业从产品、营销、组织、文化等方面形成创新的基因。默克投资全球执行副总裁、中国区总裁何慕麒认为，创新需要不断地突破和合作。内蒙古伊利实业集团股份有限公司执行总裁刘春喜认为，创新源于行业瓶颈和消费者需求，新质生产力体现在企业的科技能力和现代化水平。\n",
      "\n",
      "评论：\n",
      "\n",
      "与会嘉宾在论坛上分享了各自对创新的看法，强调了创新的重要性以及企业如何通过创新来解决问题和满足消费者需求。这些观点对于企业如何提升创新能力、推动行业发展具有一定的启示作用。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "内蒙古伊利实业集团股份有限公司（简称“公司”）于2024年1月成功发行了2024年度第一、二、三、四期超短期融资券，具体情况如下：\n",
      "■\n",
      "2024年3月28日，公司已完成2024年度第一、二、三、四期超短期融资券的兑付工作，本息兑付总额分别为人民币8,039,731,147.54元、6,028,852,459.02元、4,019,080,874.32元、8,037,678,688.52元，由银行间市场清算所股份有限公司代理划付至债券持有人指定的银行账户。\n",
      "\n",
      "评论：\n",
      "公司成功完成2024年度第一、二、三、四期超短期融资券的兑付工作，显示出公司良好的财务状况和信用水平。这有助于公司进一步拓展融资渠道，降低融资成本，提高资金使用效率，为公司未来的发展提供有力支持。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "\n",
      "伊利股份新获得一项外观设计专利授权，专利名为“包装套件（伊利枸杞红枣牛奶）”，专利申请号为CN202330405153.4，授权日为2024年3月15日。今年以来伊利股份新获得专利授权66个，较去年同期减少了60.24%。2023上半年公司在研发方面投入了3.44亿元，同比增11.7%。\n",
      "\n",
      "评论：\n",
      "\n",
      "伊利股份在研发方面持续投入，显示出公司对创新和产品研发的重视。外观设计专利的获得有助于提升产品竞争力，增加市场吸引力。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：新希望乳业近年来业绩增长，但负债率高企，全国化进程受阻。公司计划降低负债率，并调整增长策略。低温奶市场潜力大，有望改变市场格局。\n",
      "\n",
      "评论：新希望乳业应抓住低温奶市场机遇，加强产品创新和市场拓展，同时优化资本结构，降低负债率，提高盈利能力。在激烈的市场竞争中，公司需不断提升自身竞争力，以实现长期稳定发展。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "伊利集团携手中国绿化基金会及旗下品牌金领冠塞纳牧启动“伊利家园行动之梭梭保护林计划”，在内蒙古阿拉善地区种植树木，共度植树节。金领冠塞纳牧在线上发起“跟着塞纳牧一起种春天”活动，邀请家长线上为孩子认养一棵梭梭树，为荒漠化治理贡献力量。伊利集团自2016年开始实施“伊利家园行动”公益项目，致力于生态环境保护。\n",
      "\n",
      "评论：\n",
      "伊利集团通过“伊利家园行动”公益项目，积极响应政府倡议，为改善土地荒漠化、保护生物多样性做出了贡献。企业应更多地承担社会责任，参与到生态保护建设中来，共同创造人与自然和谐共处的美好未来。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "伊利集团作为中国奶业绿色发展的先行者，通过产业协同、科技创新和数字转型，积极推进全链减碳，实现高效、低碳、绿色生产。在牧场环节，伊利通过数字化转型，实现对奶牛养殖全过程的精准监控，提高效率，减少能源消耗和碳排放。在物流配送环节，伊利联合合作伙伴共同打造“全链路碳数字化系统”，实现对运输过程的精准管理和优化，降低碳排放。伊利将继续加快产业协同、科技创新和数字转型，为实现“双碳”目标和推动全球气候治理作出更大贡献。\n",
      "\n",
      "评论：伊利集团作为行业龙头企业，积极响应国家“双碳”战略需求，通过全链减碳新模式，引领行业绿色发展。在实现“降碳增效”方面，伊利通过数字化转型赋能全链运营，为行业提供了可借鉴的实践经验。伊利的绿色发展理念和行动，不仅符合国家可持续发展战略，也为全球气候治理作出了积极贡献。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "中国发展高层论坛2024年年会于2024年3月24-25日举行。在“碳中和与全球气候治理专题研讨会”上，伊利集团高级执行总裁张剑秋分享了伊利集团在推动全产业链减碳、科技创新和数字转型方面的具体实践和成果。伊利集团通过产业协同实现全链减碳，通过科技创新实现减排技术“从优到新”，通过数字转型实现降碳增效“从新到强”。张剑秋表示，可持续的能力是企业未来领导力的表现，伊利将持续探索气候治理与全链减碳的方案，为实现“双碳”目标和推动全球气候治理作出更大贡献。\n",
      "\n",
      "评论：\n",
      "伊利集团在推动全产业链减碳、科技创新和数字转型方面的实践和成果值得肯定。这些努力不仅有助于实现“双碳”目标，也有助于推动全球气候治理。希望更多的企业能够借鉴伊利的经验，共同为应对气候变化和实现可持续发展做出贡献。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "\n",
      "“伊利方舟”儿童安全公益项目携手伊利“伊心向阳”志愿者团队走进呼和浩特市土默特左旗某小学，开展“快乐护航 了不起的长大——‘伊利方舟’快乐教育嘉年华”活动，通过生动有趣的互动游戏，为孩子们送去了关注安全和情绪成长的快乐教育。该项目自2012年发起以来，已为全国600余所学校、37余万名孩子提供了安全教育，致力于培养孩子们的安全意识和提升他们的自我保护能力。\n",
      "\n",
      "评论：\n",
      "\n",
      "“伊利方舟”儿童安全公益项目通过快乐教育嘉年华的形式，为孩子们提供了关注安全和情绪成长的快乐教育，有助于提高他们的自我保护能力。该项目在拓展项目广度和深度上积极尝试，未来将通过“伊利方舟”＋“伊心向阳”的方式，进一步传播项目的安全教育理念，快乐护航更多孩子“了不起的长大”。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：君乐宝乳业集团股份有限公司正式启动IPO进程，计划在2025年完成上市，并立下500亿元的销售目标。作为中国第五大乳企，君乐宝业务范围包括婴幼儿奶粉、酸奶、低温鲜奶、常温液态奶等板块，建有25个生产工厂、25个现代化大型牧场。尽管君乐宝营收增速颇为亮眼，但资产负债率居高不下，为77.63%，远高于同行。此外，产品质量和售后服务问题频发，消费者投诉较多。\n",
      "\n",
      "评论：君乐宝在IPO进程中面临资产负债率高企、产品质量和服务问题等挑战，如何提升品牌信任度、消除消费者疑虑，将是其未来发展的关键。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "中国发展高层论坛2024年年会于3月24日在北京举行，伊利集团高级执行总裁张剑秋在“碳中和与全球气候治理”分论坛中分享了伊利引领中国奶业绿色发展的经验。伊利集团坚持以产业协同为路径，以科技创新为引领，以数字转型为动力，积极稳妥推进碳达峰碳中和，努力实现应对气候变化和推进行业高质量发展的互促共赢。为推动实现合作伙伴的低碳转型，伊利打造了行业首个“零碳联盟”，并搭建了供应商碳排放数据收集系统，2027年，伊利将实现核心供应商100%低碳转型。\n",
      "\n",
      "评论：\n",
      "伊利集团在推动绿色发展方面表现出色，通过产业协同、科技创新和数字转型等路径，积极推进碳达峰碳中和，努力实现应对气候变化和推进行业高质量发展的互促共赢。此外，伊利还打造了行业首个“零碳联盟”，并搭建了供应商碳排放数据收集系统，以推动实现合作伙伴的低碳转型。这一举措不仅有助于伊利自身实现低碳发展，也为整个行业树立了绿色发展的典范。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总结：\n",
      "\n",
      "在“两山理论”“双碳战略”指引下，中国企业特别是上市公司和国企央企，正成为建设美丽中国，实现绿色低碳、可持续发展的重要行动主体。企业社会责任理念已被联合国、非政府组织、西方发达国家及普通大众广为熟知并普遍接受，各国公司尤其是跨国企业纷纷将社会责任纳入发展战略和长远规划中。我国也高度重视企业社会责任建设。ESG不仅仅是投资策略，还是一种新的价值理念和评价工具，正在重新定义企业增长的方式。改善ESG表现，对企业发展至关重要，有助于实现长期、强劲的财务业绩，实现社会价值和商业价值的同步增长。\n",
      "\n",
      "评论：\n",
      "\n",
      "企业践行社会责任，是实现绿色低碳、可持续发展的重要途径。在ESG理念的引领下，企业应紧密结合国家大政方针和施政所向，在应对气候变化、推进绿色发展、坚持生态文明、助力乡村振兴等领域挖掘和传播优秀企业社会责任故事。同时，政府职能部门应通过政策引导，展现企业创造的社会价值，为企业可持续发展营造良好环境。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import pandas as pd\n",
    "df_news = pd.read_json('/home/userroot/dev/jiucai/crawl/sina_news/data/bak.stock_news.jsonl',lines=True)\n",
    "df_news = df_news[0:20]\n",
    "for i , news in df_news.iterrows():\n",
    "    news = news['content'][0:4000]\n",
    "    messages = [\n",
    "                \n",
    "\n",
    "                {\"role\": \"user\", \"content\": f\"从下面内容中总结内容\\n{news}\"},\n",
    "                {\"role\":\"system\", \"content\":f\"你是一名专业的投研分析人员，你的任务是进行投研分析,先总结，然后发布评论，如果无法总结，请回答不知道。评论内容在总结内容之后，以【评论】开头。全部内容不要超过150字,不允许分段。\"},\n",
    "\n",
    "            ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, return_tensors=\"pt\",truncation='only_first')\n",
    "    sampling_params = SamplingParams(temperature=0, top_p=0.95, max_tokens=300)\n",
    "    print(llm.generate(prompt,sampling_params)[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import os\n",
    "torch.cuda.device_count()\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#torch.empty(2, device='cuda')\n",
    "torch.cuda.get_device_capability()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
