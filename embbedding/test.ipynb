{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 00:06:20,184\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "\n",
    "ds = ray.data.read_json('../etl_out/partition_by_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_10 = ds.limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from transformers import AutoModel\n",
    "from llama_index.core.node_parser import  SentenceSplitter #SimpleNodeParser\n",
    "from llama_index.core.schema import Node\n",
    "from llama_index.core.schema import Document\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "def convert_documents_into_nodes(data: Dict[str, np.ndarray]) -> List[Dict[str, Node]]:\n",
    "    all_text = data['title'] + data['content']\n",
    "    documents = [ Document(text=t) for t in all_text]\n",
    "    nodes = SentenceSplitter.get_nodes_from_documents([documents])\n",
    "    return [{\"node\": node} for node in nodes]\n",
    "\n",
    "class EmbedNodes:\n",
    "    def __init__(self):\n",
    "        import os\n",
    "        os.environ['HTTPS_PROXY'] = 'http://100.109.83.118:808/'\n",
    "        self.embedding_model = HuggingFaceEmbeddings(model_name='jinaai/jina-embeddings-v2-base-zh',model_kwargs= {\"trust_remote_code\":\"True\"})\n",
    "\n",
    "    #列存储的方式\n",
    "    def __call__(self, node_batch: Dict[str, List[Node]]) -> Dict[str, List[Node]]:\n",
    "       \n",
    "        nodes = node_batch[\"node\"]\n",
    "        text = [node.text for node in nodes]\n",
    "        embeddings = self.embedding_model.embed_documents(text)\n",
    "        assert len(nodes) == len(embeddings)\n",
    "\n",
    "        for node, embedding in zip(nodes, embeddings):\n",
    "            node.embedding = embedding\n",
    "        return {\"embedded_nodes\": nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = ds.flat_map(convert_documents_into_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = nodes.map_batches(EmbedNodes, concurrency=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 00:17:32,870\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=200 for stage ReadJSON to satisfy DataContext.get_current().min_parallelism=200.\n",
      "2024-03-10 00:17:32,872\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[ReadJSON->FlatMap(convert_documents_into_nodes)->MapBatches(EmbedNodes)] -> TaskPoolMapOperator[Write]\n",
      "2024-03-10 00:17:32,873\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-10 00:17:32,875\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 00:17:33,689\tINFO actor_pool_map_operator.py:114 -- ReadJSON->FlatMap(convert_documents_into_nodes)->MapBatches(EmbedNodes): Waiting for 1 pool actors to start...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb5a88677a3477ead0e3e0934f621f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 00:17:54,966\tERROR streaming_executor_state.py:496 -- An exception was raised from a task of operator \"ReadJSON->FlatMap(convert_documents_into_nodes)->MapBatches(EmbedNodes)\". Dataset execution will now abort. To ignore this exception and continue, set DataContext.max_errored_blocks.\n",
      "2024-03-10 00:17:54,979\tWARNING actor_pool_map_operator.py:278 -- To ensure full parallelization across an actor pool of size 1, the Dataset should consist of at least 1 distinct blocks. Consider increasing the parallelism when creating the Dataset.\n"
     ]
    },
    {
     "ename": "RayTaskError(TypeError)",
     "evalue": "\u001b[36mray::ReadJSON->FlatMap(convert_documents_into_nodes)->MapBatches(EmbedNodes)()\u001b[39m (pid=107029, ip=192.168.1.35, actor_id=7c9ef0773aaf52b09f8acf8d01000000, repr=MapWorker(ReadJSON->FlatMap(convert_documents_into_nodes)->MapBatches(EmbedNodes)))\n    yield from _map_task(\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_operator.py\", line 418, in _map_task\n    for b_out in map_transformer.apply_transform(iter(blocks), ctx):\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 139, in apply_transform\n    iter = transform_fn(iter, ctx)\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 288, in __call__\n    first = next(block_iter, None)\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 371, in __call__\n    for data in iter:\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 196, in __call__\n    yield from self._row_fn(input, ctx)\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 245, in transform_fn\n    for out_row in fn(row):\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 119, in fn\n    return op_fn(item, *fn_args, **fn_kwargs)\n  File \"/tmp/ipykernel_102281/1594239249.py\", line 12, in convert_documents_into_nodes\nTypeError: NodeParser.get_nodes_from_documents() missing 1 required positional argument: 'documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(TypeError)\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43membeds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./test.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/dataset.py:2837\u001b[0m, in \u001b[0;36mDataset.write_parquet\u001b[0;34m(self, path, filesystem, try_create_dir, arrow_open_stream_args, filename_provider, block_path_provider, arrow_parquet_args_fn, ray_remote_args, **arrow_parquet_args)\u001b[0m\n\u001b[1;32m   2767\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Writes the :class:`~ray.data.Dataset` to parquet files under the provided ``path``.\u001b[39;00m\n\u001b[1;32m   2768\u001b[0m \n\u001b[1;32m   2769\u001b[0m \u001b[38;5;124;03mThe number of files is determined by the number of blocks in the dataset.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2824\u001b[0m \u001b[38;5;124;03m        block to a file.\u001b[39;00m\n\u001b[1;32m   2825\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   2826\u001b[0m datasink \u001b[38;5;241m=\u001b[39m _ParquetDatasink(\n\u001b[1;32m   2827\u001b[0m     path,\n\u001b[1;32m   2828\u001b[0m     arrow_parquet_args_fn\u001b[38;5;241m=\u001b[39marrow_parquet_args_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2835\u001b[0m     dataset_uuid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uuid,\n\u001b[1;32m   2836\u001b[0m )\n\u001b[0;32m-> 2837\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_datasink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mray_remote_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mray_remote_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/dataset.py:3633\u001b[0m, in \u001b[0;36mDataset.write_datasink\u001b[0;34m(self, datasink, ray_remote_args)\u001b[0m\n\u001b[1;32m   3629\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m   3631\u001b[0m datasink\u001b[38;5;241m.\u001b[39mon_write_start()\n\u001b[0;32m-> 3633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_ds \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogical_plan\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaterialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3634\u001b[0m blocks \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_ds\u001b[38;5;241m.\u001b[39m_plan\u001b[38;5;241m.\u001b[39mexecute()\u001b[38;5;241m.\u001b[39mget_blocks())\n\u001b[1;32m   3635\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m   3636\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(block, pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(block) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m blocks\n\u001b[1;32m   3637\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/dataset.py:4691\u001b[0m, in \u001b[0;36mDataset.materialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4672\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute and materialize this dataset into object store memory.\u001b[39;00m\n\u001b[1;32m   4673\u001b[0m \n\u001b[1;32m   4674\u001b[0m \u001b[38;5;124;03mThis can be used to read all blocks into memory. By default, Dataset\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4688\u001b[0m \u001b[38;5;124;03m    A MaterializedDataset holding the materialized data blocks.\u001b[39;00m\n\u001b[1;32m   4689\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4690\u001b[0m copy \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m, _deep_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _as\u001b[38;5;241m=\u001b[39mMaterializedDataset)\n\u001b[0;32m-> 4691\u001b[0m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce_read\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4693\u001b[0m blocks \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39m_plan\u001b[38;5;241m.\u001b[39m_snapshot_blocks\n\u001b[1;32m   4694\u001b[0m blocks_with_metadata \u001b[38;5;241m=\u001b[39m blocks\u001b[38;5;241m.\u001b[39mget_blocks_with_metadata() \u001b[38;5;28;01mif\u001b[39;00m blocks \u001b[38;5;28;01melse\u001b[39;00m []\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/plan.py:628\u001b[0m, in \u001b[0;36mExecutionPlan.execute\u001b[0;34m(self, allow_clear_input_blocks, force_read, preserve_order)\u001b[0m\n\u001b[1;32m    621\u001b[0m metrics_tag \u001b[38;5;241m=\u001b[39m create_dataset_tag(\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_uuid\n\u001b[1;32m    623\u001b[0m )\n\u001b[1;32m    624\u001b[0m executor \u001b[38;5;241m=\u001b[39m StreamingExecutor(\n\u001b[1;32m    625\u001b[0m     copy\u001b[38;5;241m.\u001b[39mdeepcopy(context\u001b[38;5;241m.\u001b[39mexecution_options),\n\u001b[1;32m    626\u001b[0m     metrics_tag,\n\u001b[1;32m    627\u001b[0m )\n\u001b[0;32m--> 628\u001b[0m blocks \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_to_legacy_block_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_clear_input_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_clear_input_blocks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_uuid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_uuid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m stats \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mget_stats()\n\u001b[1;32m    636\u001b[0m stats_summary_string \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mto_summary()\u001b[38;5;241m.\u001b[39mto_string(\n\u001b[1;32m    637\u001b[0m     include_parent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    638\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/legacy_compat.py:126\u001b[0m, in \u001b[0;36mexecute_to_legacy_block_list\u001b[0;34m(executor, plan, allow_clear_input_blocks, dataset_uuid, preserve_order)\u001b[0m\n\u001b[1;32m    119\u001b[0m dag, stats \u001b[38;5;241m=\u001b[39m _get_execution_dag(\n\u001b[1;32m    120\u001b[0m     executor,\n\u001b[1;32m    121\u001b[0m     plan,\n\u001b[1;32m    122\u001b[0m     allow_clear_input_blocks,\n\u001b[1;32m    123\u001b[0m     preserve_order,\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    125\u001b[0m bundles \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mexecute(dag, initial_stats\u001b[38;5;241m=\u001b[39mstats)\n\u001b[0;32m--> 126\u001b[0m block_list \u001b[38;5;241m=\u001b[39m \u001b[43m_bundles_to_block_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbundles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Set the stats UUID after execution finishes.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m _set_stats_uuid_recursive(executor\u001b[38;5;241m.\u001b[39mget_stats(), dataset_uuid)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/legacy_compat.py:411\u001b[0m, in \u001b[0;36m_bundles_to_block_list\u001b[0;34m(bundles)\u001b[0m\n\u001b[1;32m    409\u001b[0m blocks, metadata \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    410\u001b[0m owns_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ref_bundle \u001b[38;5;129;01min\u001b[39;00m bundles:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ref_bundle\u001b[38;5;241m.\u001b[39mowns_blocks:\n\u001b[1;32m    413\u001b[0m         owns_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/interfaces/executor.py:37\u001b[0m, in \u001b[0;36mOutputIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RefBundle:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor.py:145\u001b[0m, in \u001b[0;36mStreamingExecutor.execute.<locals>.StreamIterator.get_next\u001b[0;34m(self, output_split_idx)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_next\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_split_idx: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RefBundle:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m         item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_split_idx\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outer\u001b[38;5;241m.\u001b[39m_global_info:\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outer\u001b[38;5;241m.\u001b[39m_global_info\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m, dag\u001b[38;5;241m.\u001b[39m_estimated_output_blocks)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor_state.py:320\u001b[0m, in \u001b[0;36mOpState.get_output_blocking\u001b[0;34m(self, output_split_idx)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# Check if StreamingExecutor has caught an exception or is done execution.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finished \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutqueue\u001b[38;5;241m.\u001b[39mhas_next(output_split_idx):\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor.py:212\u001b[0m, in \u001b[0;36mStreamingExecutor.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run the control loop in a helper thread.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03mResults are returned via the output node's outqueue.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# Run scheduling loop until complete.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scheduling_loop_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_topology\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown:\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# Propagate it to the result iterator.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor.py:260\u001b[0m, in \u001b[0;36mStreamingExecutor._scheduling_loop_step\u001b[0;34m(self, topology)\u001b[0m\n\u001b[1;32m    255\u001b[0m     logger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScheduling loop step...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Note: calling process_completed_tasks() is expensive since it incurs\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# ray.wait() overhead, so make sure to allow multiple dispatch per call for\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# greater parallelism.\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m num_errored_blocks \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_completed_tasks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopology\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backpressure_policies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_errored_blocks\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_errored_blocks \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_errored_blocks \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m num_errored_blocks\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor_state.py:497\u001b[0m, in \u001b[0;36mprocess_completed_tasks\u001b[0;34m(topology, backpressure_policies, max_errored_blocks)\u001b[0m\n\u001b[1;32m    491\u001b[0m             error_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    492\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Dataset execution will now abort.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    493\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m To ignore this exception and continue, set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    494\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m DataContext.max_errored_blocks.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m             )\n\u001b[1;32m    496\u001b[0m             logger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39merror(error_message)\n\u001b[0;32m--> 497\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task, MetadataOpTask)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor_state.py:464\u001b[0m, in \u001b[0;36mprocess_completed_tasks\u001b[0;34m(topology, backpressure_policies, max_errored_blocks)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task, DataOpTask):\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         num_blocks_read \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_data_ready\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_blocks_to_read_per_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m max_blocks_to_read_per_op:\n\u001b[1;32m    468\u001b[0m             max_blocks_to_read_per_op[state] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m num_blocks_read\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/interfaces/physical_operator.py:102\u001b[0m, in \u001b[0;36mDataOpTask.on_data_ready\u001b[0;34m(self, max_blocks_to_read)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_done_callback(ex)\n\u001b[0;32m--> 102\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_ready_callback(\n\u001b[1;32m    104\u001b[0m     RefBundle([(block_ref, meta)], owns_blocks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m num_blocks_read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/interfaces/physical_operator.py:98\u001b[0m, in \u001b[0;36mDataOpTask.on_data_ready\u001b[0;34m(self, max_blocks_to_read)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# The generator should always yield 2 values (block and metadata)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# each time. If we get a StopIteration here, it means an error\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# TODO(hchen): Ray Core should have a better interface for\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# detecting and obtaining the exception.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m         \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbove ray.get should raise an exception.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:22\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     21\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/ray/_private/worker.py:2624\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2622\u001b[0m     worker\u001b[38;5;241m.\u001b[39mcore_worker\u001b[38;5;241m.\u001b[39mdump_object_store_memory_usage()\n\u001b[1;32m   2623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayTaskError):\n\u001b[0;32m-> 2624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mas_instanceof_cause()\n\u001b[1;32m   2625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2626\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[0;31mRayTaskError(TypeError)\u001b[0m: \u001b[36mray::ReadJSON->FlatMap(convert_documents_into_nodes)->MapBatches(EmbedNodes)()\u001b[39m (pid=107029, ip=192.168.1.35, actor_id=7c9ef0773aaf52b09f8acf8d01000000, repr=MapWorker(ReadJSON->FlatMap(convert_documents_into_nodes)->MapBatches(EmbedNodes)))\n    yield from _map_task(\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_operator.py\", line 418, in _map_task\n    for b_out in map_transformer.apply_transform(iter(blocks), ctx):\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 139, in apply_transform\n    iter = transform_fn(iter, ctx)\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 288, in __call__\n    first = next(block_iter, None)\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 371, in __call__\n    for data in iter:\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 196, in __call__\n    yield from self._row_fn(input, ctx)\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 245, in transform_fn\n    for out_row in fn(row):\n  File \"/home/userroot/miniconda3/envs/rag/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 119, in fn\n    return op_fn(item, *fn_args, **fn_kwargs)\n  File \"/tmp/ipykernel_102281/1594239249.py\", line 12, in convert_documents_into_nodes\nTypeError: NodeParser.get_nodes_from_documents() missing 1 required positional argument: 'documents'"
     ]
    }
   ],
   "source": [
    "embeds.write_parquet('./test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "1\n",
      "4\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print('hello')\n",
    "\n",
    "for a, b in c:\n",
    "    print(a)\n",
    "#a = [2, 5]\n",
    "print(list(c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
