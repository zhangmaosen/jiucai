{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import VectorDBQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "summary_db = None\n",
    "survey_db = None\n",
    "\n",
    "summary_embedding = None\n",
    "survey_embedding = None\n",
    "\n",
    "def update(*args):\n",
    "    global summary_embedding, survey_embedding\n",
    "    global summary_db, survey_db \n",
    "\n",
    "    [summary_db_selected, survey_db_selected] = args\n",
    "\n",
    "    model_names_map = {'mpnet':'sentence-transformers/multi-qa-mpnet-base-dot-v1', # 0\n",
    "              'e5': 'intfloat/multilingual-e5-large', # 1\n",
    "              'shibing624': 'shibing624/text2vec-base-chinese', # 2\n",
    "               'GanymedeNil':'GanymedeNil/text2vec-large-chinese', # 4\n",
    "               'all_mpnet':'sentence-transformers/all-mpnet-base-v2', # 5\n",
    "               'shibing_paraphrase':'shibing624/text2vec-base-chinese-paraphrase', # 6\n",
    "               'luotuo':'silk-road/luotuo-bert-medium',\n",
    "               'qa_mpnet':'sentence-transformers/multi-qa-mpnet-base-cos-v1', # 8\n",
    "               'my-184':'C:\\\\Users\\\\zhang\\\\dev\\\\sentence-transformers\\\\output\\\\training_paraphrases_hfl-chinese-lert-large-2023-07-18_21-11-13\\\\184',\n",
    "    }\n",
    "    \n",
    "\n",
    "    summary_model_name = model_names_map[summary_db_selected]\n",
    "    survey_model_name = model_names_map[survey_db_selected]\n",
    "\n",
    "    if 'summary_embedding' in locals() or 'summary_embedding' in globals():\n",
    "        print('clear gpu embedding memory')\n",
    "        del summary_embedding\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f'summary db is  {summary_model_name}, survey db is {survey_model_name} selected!')\n",
    "\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "    summary_embedding = HuggingFaceEmbeddings(\n",
    "        model_name=summary_model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    survey_embedding = HuggingFaceEmbeddings(\n",
    "        model_name=survey_model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "\n",
    "    relative_path = '../'\n",
    "\n",
    "    summary_db_name_pre = summary_model_name.split('/')[-1]\n",
    "    survey_db_name_pre = survey_model_name.split('/')[-1]\n",
    "\n",
    "    \n",
    "    parent_path = './embedding_dbs/'\n",
    "    summary_persist_directory = parent_path + 'summary_db_'+summary_db_name_pre+'_embedding'\n",
    "    summary_persist_directory = relative_path + summary_persist_directory\n",
    "\n",
    "    survey_persist_directory = parent_path + 'survey_db_'+survey_db_name_pre+'_embedding'\n",
    "    survey_persist_directory = relative_path + survey_persist_directory\n",
    "\n",
    "\n",
    "    summary_db = Chroma(persist_directory=summary_persist_directory, embedding_function=summary_embedding,collection_metadata={\"hnsw:space\": \"cosine\"})\n",
    "    survey_db =  Chroma(persist_directory=survey_persist_directory, embedding_function=survey_embedding,collection_metadata={\"hnsw:space\": \"cosine\"})\n",
    "    return f'load model {summary_model_name} in {summary_persist_directory} \\n load model {survey_model_name} in {survey_persist_directory}'\n",
    "    \n",
    "def greet(query):\n",
    "    summary = summary_db.similarity_search_with_score(query, k=2)\n",
    "    survey = survey_db.similarity_search_with_score(query, k=3)\n",
    "    print(f'query is {query}')\n",
    "    return summary+survey \n",
    "\n",
    "\n",
    "update('shibing_paraphrase','shibing_paraphrase')\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    model_names = ['e5','shibing624','mpnet', 'GanymedeNil', 'shibing_paraphrase', 'luotuo','qa_mpnet', 'my-184']\n",
    "    summary_db_selected = gr.Dropdown(model_names, value=\"shibing_paraphrase\", label=\"研报摘要数据库\")\n",
    "    survey_db_selected = gr.Dropdown(model_names, value=\"shibing_paraphrase\", label=\"公司调研记录数据库\")\n",
    "\n",
    "\n",
    "    refresh_button = gr.Button('load db')\n",
    "    refresh_button.click(fn=update,inputs=[summary_db_selected,survey_db_selected], outputs=gr.TextArea(lines=1))\n",
    "    with gr.Row():\n",
    "        gr.Interface(fn=greet, inputs=\"text\", outputs=[\"text\",\n",
    "                                                           \"text\",\n",
    "                                                           \"text\",\n",
    "                                                           \"text\",\n",
    "                                                           \"text\",])\n",
    "if 'demo' in locals() or 'demo' in globals():\n",
    "    demo.close()\n",
    "demo.launch(server_name=\"0.0.0.0\",share=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with gr.Blocks() as demo:\n",
    "    model_names = ['e5','shibing624','mpnet', 'GanymedeNil', 'shibing_paraphrase', 'luotuo-bert-medium', 'my-184']\n",
    "    summary_db_selected = gr.Dropdown(model_names, value=\"shibing_paraphrase\")\n",
    "    survey_db_selected = gr.Dropdown(model_names, value=\"shibing_paraphrase\")\n",
    "\n",
    "\n",
    "    refresh_button = gr.Button('load db')\n",
    "    refresh_button.click(fn=update,inputs=[summary_db_selected,survey_db_selected], outputs=gr.TextArea(lines=1))\n",
    "    with gr.Row():\n",
    "        gr.Interface(fn=greet, inputs=\"text\", outputs=[\"text\",\n",
    "                                                           \"text\",\n",
    "                                                           \"text\",\n",
    "                                                           \"text\",\n",
    "                                                           \"text\",])\n",
    "\n",
    "if 'demo' in locals() or 'demo' in globals():\n",
    "    demo.close()\n",
    " \n",
    "demo.launch(server_name=\"0.0.0.0\",share=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'my-184'\n",
    "\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=model,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "chroma_db = Chroma(persist_directory=db_dir, embedding_function=embedding,collection_metadata={\"hnsw:space\": \"cosine\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
